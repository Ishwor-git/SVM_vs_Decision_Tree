{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd22a2e",
   "metadata": {},
   "source": [
    "# Multiclass classification of Iris dataset using SVM\n",
    "we know SVM is designed for binary classification but we can use it for multiclass classification with a simple twist. Insted of classifying directly we will use One vs All approach. \n",
    "\n",
    "Steps : \n",
    "1. Train a SVM1 for  class-0 (Setosa) vs. All others\n",
    "2. Train a SVM2 for  class-1 (Versicolor) vs. All others\n",
    "3. Train a SVM3 for  class-2 (Virginica) vs. All others\n",
    "4. Predict using all 3 and choose final class based on highest probablity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b02b7a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d0ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd521b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from models.svm import LinearSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0d3fa",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac74089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 120 samples\n",
      "Test set size: 30 samples\n",
      "Number of features: 4\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291b2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization using numpy (Z-score normalization)\n",
    "# Formula: (X - mean) / std\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)\n",
    "\n",
    "# Add small epsilon to avoid division by zero\n",
    "epsilon = 1e-8\n",
    "train_std = np.where(train_std == 0, epsilon, train_std)\n",
    "\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_test = (X_test - train_mean) / train_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be03de",
   "metadata": {},
   "source": [
    "## Training 1st svm  \n",
    "Model 1: Setosa (+1) vs. All others (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ba5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 0.1048\n",
      "Epoch 200/2000, Loss: 0.0987\n",
      "Epoch 300/2000, Loss: 0.0976\n",
      "Epoch 400/2000, Loss: 0.0981\n",
      "Epoch 500/2000, Loss: 0.0978\n",
      "Epoch 600/2000, Loss: 0.0977\n",
      "Epoch 700/2000, Loss: 0.0981\n",
      "Epoch 800/2000, Loss: 0.0978\n",
      "Epoch 900/2000, Loss: 0.0977\n",
      "Epoch 1000/2000, Loss: 0.0981\n",
      "Epoch 1100/2000, Loss: 0.0978\n",
      "Epoch 1200/2000, Loss: 0.0977\n",
      "Epoch 1300/2000, Loss: 0.0981\n",
      "Epoch 1400/2000, Loss: 0.0978\n",
      "Epoch 1500/2000, Loss: 0.0977\n",
      "Epoch 1600/2000, Loss: 0.0981\n",
      "Epoch 1700/2000, Loss: 0.0978\n",
      "Epoch 1800/2000, Loss: 0.0977\n",
      "Epoch 1900/2000, Loss: 0.0981\n",
      "Epoch 2000/2000, Loss: 0.0978\n",
      "Model 1 (Setosa vs All) Train Accuracy: 1.0000\n",
      "Model 1 (Setosa vs All) Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Setosa (+1) vs. All others (-1)\n",
    "y_train_bin = np.where(y_train == 0, 1, -1)\n",
    "y_test_bin = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "svm_model1 = LinearSVM(lr=0.0005, C=1.0, epochs=2000)\n",
    "svm_model1.fit(X_train, y_train_bin)\n",
    "\n",
    "# Evaluate\n",
    "train_preds = svm_model1.predict(X_train)\n",
    "test_preds = svm_model1.predict(X_test)\n",
    "\n",
    "train_acc = np.mean(train_preds == y_train_bin)\n",
    "test_acc = np.mean(test_preds == y_test_bin)\n",
    "\n",
    "print(f\"Model 1 (Setosa vs All) Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Model 1 (Setosa vs All) Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41322a7f",
   "metadata": {},
   "source": [
    "## Training 2nd svm  \n",
    "Model 2 : Versicolor (+1) vs. All others (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d9664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 56.7228\n",
      "Epoch 200/2000, Loss: 56.6112\n",
      "Epoch 300/2000, Loss: 56.5958\n",
      "Epoch 400/2000, Loss: 56.6012\n",
      "Epoch 500/2000, Loss: 56.6031\n",
      "Epoch 600/2000, Loss: 56.5853\n",
      "Epoch 700/2000, Loss: 56.5997\n",
      "Epoch 800/2000, Loss: 56.5838\n",
      "Epoch 900/2000, Loss: 56.5904\n",
      "Epoch 1000/2000, Loss: 56.5629\n",
      "Epoch 1100/2000, Loss: 56.5810\n",
      "Epoch 1200/2000, Loss: 56.6012\n",
      "Epoch 1300/2000, Loss: 56.5845\n",
      "Epoch 1400/2000, Loss: 56.5711\n",
      "Epoch 1500/2000, Loss: 56.5978\n",
      "Epoch 1600/2000, Loss: 56.6042\n",
      "Epoch 1700/2000, Loss: 56.6046\n",
      "Epoch 1800/2000, Loss: 56.5734\n",
      "Epoch 1900/2000, Loss: 56.5811\n",
      "Epoch 2000/2000, Loss: 56.5716\n",
      "Model 2 (Versicolor vs All) Train Accuracy: 0.7500\n",
      "Model 2 (Versicolor vs All) Test Accuracy: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Versicolor (+1) vs. All others (-1)\n",
    "y_train_bin2 = np.where(y_train == 1, 1, -1)\n",
    "y_test_bin2 = np.where(y_test == 1, 1, -1)\n",
    "\n",
    "svm_model2 = LinearSVM(lr=0.0001, C=100.0, epochs=2000)\n",
    "svm_model2.fit(X_train, y_train_bin2)\n",
    "\n",
    "# Evaluate\n",
    "train_preds2 = svm_model2.predict(X_train)\n",
    "test_preds2 = svm_model2.predict(X_test)\n",
    "\n",
    "train_acc2 = np.mean(train_preds2 == y_train_bin2)\n",
    "test_acc2 = np.mean(test_preds2 == y_test_bin2)\n",
    "\n",
    "print(f\"Model 2 (Versicolor vs All) Train Accuracy: {train_acc2:.4f}\")\n",
    "print(f\"Model 2 (Versicolor vs All) Test Accuracy: {test_acc2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73b64b",
   "metadata": {},
   "source": [
    "## Training 3rd svm  \n",
    "Model 3: Virginica (+1) vs. All others (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1db7d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 0.4289\n",
      "Epoch 200/2000, Loss: 0.4246\n",
      "Epoch 300/2000, Loss: 0.4278\n",
      "Epoch 400/2000, Loss: 0.4278\n",
      "Epoch 500/2000, Loss: 0.4280\n",
      "Epoch 600/2000, Loss: 0.4281\n",
      "Epoch 700/2000, Loss: 0.4280\n",
      "Epoch 800/2000, Loss: 0.4281\n",
      "Epoch 900/2000, Loss: 0.4276\n",
      "Epoch 1000/2000, Loss: 0.4278\n",
      "Epoch 1100/2000, Loss: 0.4280\n",
      "Epoch 1200/2000, Loss: 0.4281\n",
      "Epoch 1300/2000, Loss: 0.4280\n",
      "Epoch 1400/2000, Loss: 0.4281\n",
      "Epoch 1500/2000, Loss: 0.4276\n",
      "Epoch 1600/2000, Loss: 0.4278\n",
      "Epoch 1700/2000, Loss: 0.4280\n",
      "Epoch 1800/2000, Loss: 0.4281\n",
      "Epoch 1900/2000, Loss: 0.4280\n",
      "Epoch 2000/2000, Loss: 0.4281\n",
      "Model 3 (Virginica vs All) Train Accuracy: 0.8917\n",
      "Model 3 (Virginica vs All) Test Accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Virginica (+1) vs. All others (-1)\n",
    "y_train_bin3 = np.where(y_train == 2, 1, -1)\n",
    "y_test_bin3 = np.where(y_test == 2, 1, -1)\n",
    "\n",
    "svm_model3 = LinearSVM(lr=0.0005, C=1.0, epochs=2000)\n",
    "svm_model3.fit(X_train, y_train_bin3)\n",
    "\n",
    "# Evaluate\n",
    "train_preds3 = svm_model3.predict(X_train)\n",
    "test_preds3 = svm_model3.predict(X_test)\n",
    "\n",
    "train_acc3 = np.mean(train_preds3 == y_train_bin3)\n",
    "test_acc3 = np.mean(test_preds3 == y_test_bin3)\n",
    "\n",
    "print(f\"Model 3 (Virginica vs All) Train Accuracy: {train_acc3:.4f}\")\n",
    "print(f\"Model 3 (Virginica vs All) Test Accuracy: {test_acc3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b93cf",
   "metadata": {},
   "source": [
    "## Final classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f811af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final multi-class Test Accuracy: 0.7667\n"
     ]
    }
   ],
   "source": [
    "# Collect decision scores from each one-vs-all model\n",
    "scores_1 = svm_model1.decision_function(X_test)  # Setosa\n",
    "scores_2 = svm_model2.decision_function(X_test)  # Versicolor\n",
    "scores_3 = svm_model3.decision_function(X_test)  # Virginica\n",
    "\n",
    "# Stack scores: shape (n_samples, 3)\n",
    "scores = np.vstack([scores_1, scores_2, scores_3]).T\n",
    "\n",
    "# Pick class with highest score\n",
    "pred_class = np.argmax(scores, axis=1)  # 0=setosa, 1=versicolor, 2=virginica\n",
    "\n",
    "# Evaluate\n",
    "final_acc = np.mean(pred_class == y_test)\n",
    "print(f\"Final multi-class Test Accuracy: {final_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6d35a",
   "metadata": {},
   "source": [
    "## Visualize Decision Boundaries using PCA\n",
    "Reduce 4D data to 2D using PCA for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720acfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement PCA from scratch using numpy\n",
    "def pca_transform(X, n_components=2):\n",
    "    \"\"\"\n",
    "    Apply PCA to reduce dimensionality\n",
    "    X: data matrix (n_samples, n_features)\n",
    "    n_components: number of principal components\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    \n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = np.cov(X_centered.T)\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    # Sort by eigenvalues in descending order\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    \n",
    "    # Select top n_components eigenvectors\n",
    "    components = eigenvectors[:, :n_components]\n",
    "    \n",
    "    # Project data onto principal components\n",
    "    X_pca = np.dot(X_centered, components)\n",
    "    \n",
    "    return X_pca, components, np.mean(X, axis=0)\n",
    "\n",
    "# Apply PCA to training data (already standardized)\n",
    "X_train_pca, pca_components, pca_mean = pca_transform(X_train, n_components=2)\n",
    "\n",
    "# Transform test data using same PCA components\n",
    "X_test_centered = X_test - pca_mean\n",
    "X_test_pca = np.dot(X_test_centered, pca_components)\n",
    "\n",
    "print(f\"Original shape: {X_train.shape}\")\n",
    "print(f\"PCA reduced shape: {X_train_pca.shape}\")\n",
    "print(f\"Explained variance ratio (approx): {np.var(X_train_pca, axis=0) / np.sum(np.var(X_train, axis=0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 3 SVM models on PCA-reduced data\n",
    "models_pca = []\n",
    "class_names = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "for class_idx in range(3):\n",
    "    y_train_bin_pca = np.where(y_train == class_idx, 1, -1)\n",
    "    \n",
    "    model_pca = LinearSVM(lr=0.001, C=1.0, epochs=1000)\n",
    "    \n",
    "    # Train without printing\n",
    "    model_pca.w = np.zeros(2)\n",
    "    model_pca.b = 0.0\n",
    "    \n",
    "    for epoch in range(model_pca.epochs):\n",
    "        for idx, x_i in enumerate(X_train_pca):\n",
    "            margin = y_train_bin_pca[idx] * (np.dot(x_i, model_pca.w) + model_pca.b)\n",
    "            if margin >= 1:\n",
    "                dw = model_pca.w\n",
    "                db = 0\n",
    "            else:\n",
    "                dw = model_pca.w - model_pca.C * y_train_bin_pca[idx] * x_i\n",
    "                db = -model_pca.C * y_train_bin_pca[idx]\n",
    "            model_pca.w -= model_pca.lr * dw\n",
    "            model_pca.b -= model_pca.lr * db\n",
    "    \n",
    "    models_pca.append(model_pca)\n",
    "    print(f\"Model {class_idx+1} ({class_names[class_idx]}) trained on PCA data\")\n",
    "\n",
    "# Evaluate on PCA test data\n",
    "scores_pca = np.zeros((X_test_pca.shape[0], 3))\n",
    "for i, model in enumerate(models_pca):\n",
    "    scores_pca[:, i] = model.decision_function(X_test_pca)\n",
    "\n",
    "pred_class_pca = np.argmax(scores_pca, axis=1)\n",
    "pca_acc = np.mean(pred_class_pca == y_test)\n",
    "print(f\"\\nPCA-based multi-class Test Accuracy: {pca_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
